\section{Заключение}
\label{sec:conclusion}

В данной работе представлен алгоритм, позволяющий улучшить поисковую выдачу над уже пред-обученной нейронной моделью векторного отображения, 
позволяя с одной стороны сохранить полноту выдачу ключевых слов, а с другой повысить непосредственно саму точность \textit{HitRate@k}. Представлена функция ранжирования и 
обоснованы ее основные преимущества по сравнению с обычными персечениями токенов. Произведено сравнение с базовым поиском ветокрной моделью, гибридным поиском (с подбором наилучшего парамтера сглаживания), 
а также даны рекомендации по самому подходу к выявлению ключевых слов.

Производительность алгоритма не меняется при использовании в режиме реального времени, однако, на этапе индексации (offline), при использовании 
больших языковых моделей \href{https://en.wikipedia.org/wiki/Large_language_model}{LLM} время на индексацию увеличивается кратно. Тем не менее, при использовании детерменированных алгоритмов извлечения ключевых слов, 
таких как, например \textit{YAKE} \cite{YAKE} или же, вовсе, использование самого текста параграфа, как набора ключевых слов, \underline{не увеличивает} время индексации и работает асимптотически также, как и обычный векторный поиск.

В наших тестах на данных $D_v$ \cite{}, где набор параграфов лингвистически и стилистически простой и описан в виде фактологических предложений - результат работы алгоритма не ухудшается ($HitRate@k \pm 1\%$), если в качестве ключевых слов брать текст самого параграфа. 
На наборе $D_u$, однако, результаты ухудшаются. Как видно из таблиц \ref{tab:hitrate-small} \ref{tab:hitrate-base} \ref{tab:hitrate-large}, метрики на всех моделях при сравнении на $D_u$ и $D_v$ отличаются минимум в $2$ раза, что говорит о том, что лексический сдвиг и, пред-обученность модели мало смогут помочь, 
если данные, на которых будет применяться поиск, будут близки по морфологически сложными и крайне мало отличаться друг от друга.